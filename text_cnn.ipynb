{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"YUo1gsHjoX6U","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1684725433916,"user_tz":-480,"elapsed":30010,"user":{"displayName":"ほりきょうこ","userId":"10297619547080941029"}},"outputId":"da045529-ae8c-481c-8610-286b4a2efa73"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive/')\n","import os\n","# 此处为google drive中的文件路径,drive为之前指定的工作根目录，要加上\n","os.chdir(\"/content/drive/My Drive/罪名预测\") "]},{"cell_type":"code","execution_count":2,"metadata":{"id":"P73WA4KPoFr8","executionInfo":{"status":"ok","timestamp":1684725442160,"user_tz":-480,"elapsed":5378,"user":{"displayName":"ほりきょうこ","userId":"10297619547080941029"}}},"outputs":[],"source":["import torch\n","from torch.utils.data import TensorDataset\n","from torch.utils.data import DataLoader\n","import pickle\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"kGuGOWvCHNW7","executionInfo":{"status":"ok","timestamp":1684725453130,"user_tz":-480,"elapsed":9377,"user":{"displayName":"ほりきょうこ","userId":"10297619547080941029"}}},"outputs":[],"source":["num_words = 80000\n","maxlen = 400\n","device = \"cuda\" if torch.cuda.is_available else \"cpu\"\n","# fact数据集\n","fact_test = torch.Tensor(np.load('./data_deal/test_big_fact_pad_seq_%d_%d.npy' % (num_words, maxlen))).to(device)\n","fact_train = torch.Tensor(np.load('./data_deal/big_fact_pad_seq_%d_%d.npy' % (num_words, maxlen))).to(device)\n","\n","# 标签数据集\n","labels_test = torch.Tensor(np.load('./data_deal/test_big_labels_accusation.npy')).to(device)\n","labels_train = torch.Tensor(np.load('./data_deal/big_labels_accusation.npy')).to(device)"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1684725454898,"user":{"displayName":"ほりきょうこ","userId":"10297619547080941029"},"user_tz":-480},"id":"x4vM_JZ7oFsC","outputId":"7e1a7064-e2e8-4225-f965-eea3c8b6fa9d"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([154592, 400])\n","torch.Size([154592, 195])\n","torch.Size([32508, 400])\n","torch.Size([32508, 195])\n"]}],"source":["print(fact_train.shape)\n","print(labels_train.shape)\n","print(fact_test.shape)\n","print(labels_test.shape)"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"_joKRToroFsD","executionInfo":{"status":"ok","timestamp":1684730923685,"user_tz":-480,"elapsed":512,"user":{"displayName":"ほりきょうこ","userId":"10297619547080941029"}}},"outputs":[],"source":["train_ds = TensorDataset(fact_train, labels_train)\n","train_dl = DataLoader(train_ds, batch_size = 128, shuffle = True)\n","\n","test_ds = TensorDataset(fact_test, labels_test)\n","test_dl = DataLoader(test_ds, batch_size = 128, shuffle = True)"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"pqzYZ19foFsD","executionInfo":{"status":"ok","timestamp":1684730927521,"user_tz":-480,"elapsed":494,"user":{"displayName":"ほりきょうこ","userId":"10297619547080941029"}}},"outputs":[],"source":["class GlobalMaxPool1d(nn.Module):\n","  # 通过普通的池化来实现全局池化\n","    def __init__(self):\n","        super(GlobalMaxPool1d, self).__init__()\n","    def forward(self, x):\n","         # x shape: (batch_size, channel, seq_len)\n","        return F.max_pool1d(x, kernel_size=x.shape[2]) # shape: (batch_size, channel, 1)\n","\n","class TextCNN(nn.Module):\n","    def __init__(self, vocab_size, embedding_dim, kernel_sizes, num_channels):\n","        super(TextCNN, self).__init__()\n","        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)  \n","        # self.word_embeddings = self.word_embeddings.from_pretrained(vectors, freeze=False)\n","        self.dropout = nn.Dropout(0.5)\n","        self.decoder = nn.Linear(sum(num_channels), 195)\n","        # 时序最大池化层没有权重，所以可以共用一个实例\n","        self.pool = GlobalMaxPool1d()\n","        self.convs = nn.ModuleList()  # 创建多个一维卷积层\n","        for c, k in zip(num_channels, kernel_sizes):\n","            self.convs.append(nn.Conv1d(in_channels = embedding_dim, \n","                                        out_channels = c, \n","                                        kernel_size = k))\n","\n","    def forward(self, sentence):\n","        embeds = self.word_embeddings(sentence.long())\n","        embeds = embeds.permute(0, 2, 1)\n","        # 对于每个一维卷积层，在时序最大池化后会得到一个形状为(批量大小, 通道大小, 1)的\n","        # Tensor。使用flatten函数去掉最后一维，然后在通道维上连结\n","        encoding = torch.cat([self.pool(F.relu(conv(embeds))).squeeze(-1) for conv in self.convs], dim=1)\n","        # 应用丢弃法后使用全连接层得到输出\n","        outputs = self.decoder(self.dropout(encoding))\n","        return outputs\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EQTltsYGoFsF","outputId":"11055445-e7dc-4235-ae20-56a12fde2afb"},"outputs":[{"output_type":"stream","name":"stdout","text":["TextCNN(\n","  (word_embeddings): Embedding(80000, 400)\n","  (dropout): Dropout(p=0.5, inplace=False)\n","  (decoder): Linear(in_features=900, out_features=195, bias=True)\n","  (pool): GlobalMaxPool1d()\n","  (convs): ModuleList(\n","    (0): Conv1d(400, 300, kernel_size=(3,), stride=(1,))\n","    (1): Conv1d(400, 300, kernel_size=(4,), stride=(1,))\n","    (2): Conv1d(400, 300, kernel_size=(5,), stride=(1,))\n","  )\n",")\n","epoch: 0, Train Loss: 4.681077, Train Acc: 0.055947, Eval Acc: 0.127476\n","epoch: 1, Train Loss: 2.110799, Train Acc: 0.133319, Eval Acc: 0.260982\n","epoch: 2, Train Loss: 1.284687, Train Acc: 0.230452, Eval Acc: 0.370801\n","epoch: 3, Train Loss: 0.870576, Train Acc: 0.318386, Eval Acc: 0.425834\n","epoch: 4, Train Loss: 0.629788, Train Acc: 0.381275, Eval Acc: 0.465732\n","epoch: 5, Train Loss: 0.479988, Train Acc: 0.423521, Eval Acc: 0.495540\n","epoch: 6, Train Loss: 0.381327, Train Acc: 0.455573, Eval Acc: 0.514550\n","epoch: 7, Train Loss: 0.313551, Train Acc: 0.478246, Eval Acc: 0.530608\n","epoch: 8, Train Loss: 0.264270, Train Acc: 0.498829, Eval Acc: 0.545712\n","epoch: 9, Train Loss: 0.226559, Train Acc: 0.515803, Eval Acc: 0.555740\n","epoch: 10, Train Loss: 0.197466, Train Acc: 0.532990, Eval Acc: 0.565338\n","epoch: 11, Train Loss: 0.173947, Train Acc: 0.546911, Eval Acc: 0.577673\n","epoch: 12, Train Loss: 0.154647, Train Acc: 0.559311, Eval Acc: 0.583826\n","epoch: 13, Train Loss: 0.138877, Train Acc: 0.571886, Eval Acc: 0.590193\n","epoch: 14, Train Loss: 0.125515, Train Acc: 0.581168, Eval Acc: 0.595669\n","epoch: 15, Train Loss: 0.114196, Train Acc: 0.589028, Eval Acc: 0.600006\n","epoch: 16, Train Loss: 0.104527, Train Acc: 0.598239, Eval Acc: 0.608220\n","epoch: 17, Train Loss: 0.096076, Train Acc: 0.606254, Eval Acc: 0.612557\n","epoch: 18, Train Loss: 0.088767, Train Acc: 0.613893, Eval Acc: 0.617140\n","epoch: 19, Train Loss: 0.082411, Train Acc: 0.620356, Eval Acc: 0.623846\n","epoch: 20, Train Loss: 0.076681, Train Acc: 0.627749, Eval Acc: 0.626154\n","epoch: 21, Train Loss: 0.071625, Train Acc: 0.632743, Eval Acc: 0.629445\n","epoch: 22, Train Loss: 0.067118, Train Acc: 0.641831, Eval Acc: 0.634736\n","epoch: 23, Train Loss: 0.062997, Train Acc: 0.644852, Eval Acc: 0.636397\n","epoch: 24, Train Loss: 0.059290, Train Acc: 0.651508, Eval Acc: 0.640704\n","epoch: 25, Train Loss: 0.055991, Train Acc: 0.655648, Eval Acc: 0.643011\n","epoch: 26, Train Loss: 0.052890, Train Acc: 0.661166, Eval Acc: 0.646641\n","epoch: 27, Train Loss: 0.050194, Train Acc: 0.665144, Eval Acc: 0.646856\n","epoch: 28, Train Loss: 0.047637, Train Acc: 0.668832, Eval Acc: 0.651717\n","epoch: 29, Train Loss: 0.045298, Train Acc: 0.673146, Eval Acc: 0.654762\n"]}],"source":["device = \"cuda\" if torch.cuda.is_available else \"cpu\"\n","num_words = 80000\n","maxlen = 400\n","embedding_dim, kernel_sizes, num_channels = 400, [3, 4, 5], [300, 300, 300]\n","model = TextCNN(num_words, embedding_dim, kernel_sizes, num_channels).to(device)\n","print(model)\n","\n","loss_func = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr = 1e-5)\n","\n","train_losses = []\n","train_acces = []\n","# 用数组保存每一轮迭代中，在测试数据上测试的损失值和精确度，也是为了通过画图展示出来。\n","eval_losses = []\n","eval_acces = []\n","batch_count = 0\n","for epoch in range(100):\n","    train_loss = 0\n","    train_acc = 0\n","    n1=0\n","    model.train()   # 训练模型\n","    num_correct = 0\n","    for fact, label in train_dl:\n","        # fact = fact.permute(1,0)    # fact转置\n","        out = model(fact)\n","        # print(label.shape)\n","        # print(out.shape)\n","        loss = loss_func(out, label)\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        # 记录误差\n","        train_loss += loss.item()\n","        # 计算分类的准确率\n","        # print(\"out.argmax(dim=1): \", out.argmax(dim=1),'\\n',out.argmax(dim=1).shape)\n","        # print(\"label: \",label,\"\\n\",label.shape)\n","        num_correct += (out.argmax(dim=1) == label.argmax(dim=1)).sum().item()\n","        # out.max()[1]取出概率最大值的索引位置\n","        n1 += label.shape[0]\n","        # print(\"num_correct:\", num_correct,\"\\nn1: \",n1)\n","        batch_count += 1\n","    train_losses.append(train_loss / batch_count)\n","    train_acces.append(num_correct/n1)\n","\n","    acc_sum, n = 0.0, 0\n","    with torch.no_grad():\n","        for X, y in test_dl:\n","            # X = X.permute(1,0)    # fact转置\n","            if isinstance(model, torch.nn.Module):\n","                model.eval() # 评估模式, 这会关闭dropout\n","                acc_sum += (model(X).argmax(dim=1) == y.argmax(dim=1)).float().sum().item()\n","                model.train() # 改回训练模式\n","            else: # 自定义的模型\n","                if('is_training' in model.__code__.co_varnames): # 如果有is_training这个参数\n","                    # 将is_training设置成False\n","                    acc_sum += (model(X, is_training=False).argmax(dim=1) == y.argmax(dim=1)).float().sum().item() \n","                else:\n","                    acc_sum += (model(X).argmax(dim=1) == y.argmax(dim=1)).float().sum().item() \n","            n += y.shape[0]\n","        eval_acces.append(acc_sum / n)\n","    \n","    print('epoch: {}, Train Loss: {:.6f}, Train Acc: {:.6f}, Eval Acc: {:.6f}'\n","          .format(epoch, train_loss/batch_count, num_correct/n1, acc_sum / n))\n","    if epoch%5 == 1:\n","      torch.save(model.state_dict(),\"./model/train_dict/model_dict_{0}_acc:{1}.pth\".format(epoch, acc_sum / n))\n","      torch.save(model,\"./model/model_test/model_{0}_acc:{1}.pth\".format(epoch, acc_sum / n))\n","\n","\n","print('训练完成')\n","plt.plot(np.arange(len(train_losses)), train_losses,label=\"train loss\")\n","\n","plt.plot(np.arange(len(train_acces)), train_acces, label=\"train acc\")\n","\n","plt.plot(np.arange(len(eval_losses)), eval_losses, label=\"eval loss\")\n","\n","plt.plot(np.arange(len(eval_acces)), eval_acces, label=\"eval acc\")\n","plt.legend() #显示图例\n","plt.xlabel('epoches')\n","#plt.ylabel(\"epoch\")\n","plt.title('Model accuracy&loss')\n","plt.show()\n","torch.save(model,'model.pth')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ODBabZ-mom0C","colab":{"base_uri":"https://localhost:8080/","height":175},"executionInfo":{"status":"error","timestamp":1684675709189,"user_tz":-480,"elapsed":5,"user":{"displayName":"Goodman Christian","userId":"07860743651497236067"}},"outputId":"f5250ece-52d9-4d1a-ad95-29d89cf87297"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-b14eba65aaa3>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'model.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"]}],"source":["torch.save(model,'model.pth')"]}],"metadata":{"colab":{"gpuType":"T4","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"orig_nbformat":4,"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}